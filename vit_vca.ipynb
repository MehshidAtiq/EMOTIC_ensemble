{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-dPinDpihz1",
        "outputId": "5147a0ba-4a3f-4812-ff35-24d89fd8e38a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vision_transformer'...\n",
            "remote: Enumerating objects: 1097, done.\u001b[K\n",
            "remote: Counting objects: 100% (308/308), done.\u001b[K\n",
            "remote: Compressing objects: 100% (160/160), done.\u001b[K\n",
            "remote: Total 1097 (delta 192), reused 199 (delta 140), pack-reused 789 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1097/1097), 141.93 MiB | 23.53 MiB/s, done.\n",
            "Resolving deltas: 100% (594/594), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/google-research/vision_transformer.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tf-keras\n",
        "!pip install tf-keras==2.18.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYPxQuvJjAVW",
        "outputId": "0d239d20-b258-4a2d-f9de-06f9e743e966"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tf_keras 2.17.0\n",
            "Uninstalling tf_keras-2.17.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/tf_keras-2.17.0.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/tf_keras/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled tf_keras-2.17.0\n",
            "Collecting tf-keras==2.18.0\n",
            "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting tensorflow<2.19,>=2.18 (from tf-keras==2.18.0)\n",
            "  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18->tf-keras==2.18.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18->tf-keras==2.18.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18->tf-keras==2.18.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18->tf-keras==2.18.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18->tf-keras==2.18.0) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18->tf-keras==2.18.0) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18->tf-keras==2.18.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18->tf-keras==2.18.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18->tf-keras==2.18.0) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18->tf-keras==2.18.0) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18->tf-keras==2.18.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18->tf-keras==2.18.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18->tf-keras==2.18.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18->tf-keras==2.18.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18->tf-keras==2.18.0) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18->tf-keras==2.18.0) (1.68.1)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow<2.19,>=2.18->tf-keras==2.18.0)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18->tf-keras==2.18.0) (3.5.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18->tf-keras==2.18.0) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18->tf-keras==2.18.0) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18->tf-keras==2.18.0) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18->tf-keras==2.18.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras==2.18.0) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras==2.18.0) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras==2.18.0) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras==2.18.0) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras==2.18.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras==2.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras==2.18.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras==2.18.0) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras==2.18.0) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras==2.18.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras==2.18.0) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras==2.18.0) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras==2.18.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras==2.18.0) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras==2.18.0) (0.1.2)\n",
            "Downloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboard, tensorflow, tf-keras\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "Successfully installed tensorboard-2.18.0 tensorflow-2.18.0 tf-keras-2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd vision_transformer && pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyT3lSUCjGal",
        "outputId": "455d2395-4c2b-4cb1-f390-0c1b521b2a15"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/vision_transformer\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flaxformer@ git+https://github.com/google/flaxformer (from vit_jax==0.0.8)\n",
            "  Cloning https://github.com/google/flaxformer to /tmp/pip-install-q20uhq8k/flaxformer_3302e5e516fd4b6ab1676666dc6f496f\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/google/flaxformer /tmp/pip-install-q20uhq8k/flaxformer_3302e5e516fd4b6ab1676666dc6f496f\n",
            "  Resolved https://github.com/google/flaxformer to commit 399ea3a85e9807ada653fd0de1a9de627eb0acde\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from vit_jax==0.0.8) (1.4.0)\n",
            "Collecting aqtp!=0.1.1 (from vit_jax==0.0.8)\n",
            "  Downloading aqtp-0.8.2-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting clu (from vit_jax==0.0.8)\n",
            "  Downloading clu-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from vit_jax==0.0.8) (0.8.0)\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (from vit_jax==0.0.8) (0.8.5)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from vit_jax==0.0.8) (0.4.33)\n",
            "Collecting ml-collections (from vit_jax==0.0.8)\n",
            "  Downloading ml_collections-1.0.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vit_jax==0.0.8) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from vit_jax==0.0.8) (24.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from vit_jax==0.0.8) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from vit_jax==0.0.8) (1.13.1)\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.10/dist-packages (from vit_jax==0.0.8) (4.9.7)\n",
            "Requirement already satisfied: tensorflow_probability in /usr/local/lib/python3.10/dist-packages (from vit_jax==0.0.8) (0.24.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from vit_jax==0.0.8) (2.18.0)\n",
            "Collecting tensorflow_text (from vit_jax==0.0.8)\n",
            "  Downloading tensorflow_text-2.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from vit_jax==0.0.8) (4.67.1)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from aqtp!=0.1.1->vit_jax==0.0.8) (0.4.33)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.10/dist-packages (from clu->vit_jax==0.0.8) (1.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from clu->vit_jax==0.0.8) (4.12.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from clu->vit_jax==0.0.8) (1.17.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax->vit_jax==0.0.8) (1.1.0)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax->vit_jax==0.0.8) (0.2.4)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax->vit_jax==0.0.8) (0.6.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax->vit_jax==0.0.8) (0.1.71)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax->vit_jax==0.0.8) (13.9.4)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax->vit_jax==0.0.8) (6.0.2)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->vit_jax==0.0.8) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->vit_jax==0.0.8) (3.4.0)\n",
            "Requirement already satisfied: chex>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from flaxformer@ git+https://github.com/google/flaxformer->vit_jax==0.0.8) (0.1.88)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from ml-collections->vit_jax==0.0.8) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->vit_jax==0.0.8) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->vit_jax==0.0.8) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->vit_jax==0.0.8) (2024.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->vit_jax==0.0.8) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow->vit_jax==0.0.8) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->vit_jax==0.0.8) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->vit_jax==0.0.8) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->vit_jax==0.0.8) (18.1.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->vit_jax==0.0.8) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->vit_jax==0.0.8) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->vit_jax==0.0.8) (75.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->vit_jax==0.0.8) (2.5.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->vit_jax==0.0.8) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.10/dist-packages (from tensorflow->vit_jax==0.0.8) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->vit_jax==0.0.8) (3.5.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->vit_jax==0.0.8) (3.12.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->vit_jax==0.0.8) (0.37.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets->vit_jax==0.0.8) (8.1.7)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets->vit_jax==0.0.8) (0.1.8)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets->vit_jax==0.0.8) (4.2.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets->vit_jax==0.0.8) (2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets->vit_jax==0.0.8) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets->vit_jax==0.0.8) (17.0.0)\n",
            "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets->vit_jax==0.0.8) (0.1.6)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets->vit_jax==0.0.8) (1.13.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets->vit_jax==0.0.8) (0.10.2)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets->vit_jax==0.0.8) (0.5.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->vit_jax==0.0.8) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->vit_jax==0.0.8) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->vit_jax==0.0.8) (0.45.1)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.4->flaxformer@ git+https://github.com/google/flaxformer->vit_jax==0.0.8) (0.12.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets->vit_jax==0.0.8) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets->vit_jax==0.0.8) (6.4.5)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow_datasets->vit_jax==0.0.8) (3.21.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow->vit_jax==0.0.8) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow->vit_jax==0.0.8) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow->vit_jax==0.0.8) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow->vit_jax==0.0.8) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow->vit_jax==0.0.8) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow->vit_jax==0.0.8) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax->vit_jax==0.0.8) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax->vit_jax==0.0.8) (2.18.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->vit_jax==0.0.8) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->vit_jax==0.0.8) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->vit_jax==0.0.8) (3.1.3)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->vit_jax==0.0.8) (1.6.0)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->vit_jax==0.0.8) (4.11.0)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow_datasets->vit_jax==0.0.8) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow_datasets->vit_jax==0.0.8) (1.66.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax->vit_jax==0.0.8) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow->vit_jax==0.0.8) (3.0.2)\n",
            "Downloading aqtp-0.8.2-py3-none-any.whl (894 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m894.1/894.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading clu-0.0.12-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_collections-1.0.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_text-2.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: vit_jax, flaxformer\n",
            "  Building wheel for vit_jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vit_jax: filename=vit_jax-0.0.8-py3-none-any.whl size=60961 sha256=ef15584fd503ec38deec49892465b7c00c8e309e0adcd815769785fccf368f10\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yynubvgk/wheels/f9/c6/14/3f8110236de10515440d0a4f6f52564e427ad6b48ef968883d\n",
            "  Building wheel for flaxformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flaxformer: filename=flaxformer-0.8.8-py3-none-any.whl size=323605 sha256=a632b4fbb369ae9d197777a293b13025650d59ac66299c6e86bce18a24df4155\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yynubvgk/wheels/92/28/c3/a5ec203c08082d1e7297c97ed4519688c6fa12a73c84052cca\n",
            "Successfully built vit_jax flaxformer\n",
            "Installing collected packages: ml-collections, tensorflow_text, clu, aqtp, flaxformer, vit_jax\n",
            "Successfully installed aqtp-0.8.2 clu-0.0.12 flaxformer-0.8.8 ml-collections-1.0.0 tensorflow_text-2.18.1 vit_jax-0.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"magdawjcicka/emotic\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YngMssrhjl4G",
        "outputId": "1cc1bf6c-3078-401c-9c8a-5620700e9abb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/magdawjcicka/emotic?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.16G/6.16G [01:18<00:00, 83.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/magdawjcicka/emotic/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# -------------------------\n",
        "# Transformations for images\n",
        "# -------------------------\n",
        "def get_transform():\n",
        "    \"\"\"\n",
        "    Returns the transformations for preprocessing images.\n",
        "    \"\"\"\n",
        "    return transforms.Compose([\n",
        "        transforms.ToPILImage(),  # Convert NumPy array to PIL image\n",
        "        transforms.Resize((224, 224)),  # Resize to 224x224\n",
        "        transforms.ToTensor(),  # Convert to PyTorch tensor\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet stats\n",
        "    ])\n",
        "\n",
        "# -------------------------\n",
        "# Dataset for EMOTIC data\n",
        "# -------------------------\n",
        "class EMOTICDataset(Dataset):\n",
        "    def __init__(self, annotations, img_dir, transform=None, num_categories=26):\n",
        "        \"\"\"\n",
        "        Dataset for loading EMOTIC data.\n",
        "\n",
        "        Args:\n",
        "            annotations (list): List of annotations containing filenames and categories.\n",
        "            img_dir (str): Directory containing the images.\n",
        "            transform (callable, optional): Transformations to apply to images.\n",
        "            num_categories (int): Number of categories for multi-label classification.\n",
        "        \"\"\"\n",
        "        self.annotations = annotations\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.num_categories = num_categories\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        entry = self.annotations[idx]\n",
        "        img_path = os.path.join(self.img_dir, entry['filename'])\n",
        "\n",
        "        if not os.path.exists(img_path):\n",
        "            raise FileNotFoundError(f\"File not found: {img_path}\")\n",
        "\n",
        "        image = np.load(img_path)  # Load image as a NumPy array\n",
        "\n",
        "        # Ensure the image is RGB\n",
        "        if len(image.shape) == 2:\n",
        "            image = np.stack([image] * 3, axis=-1)  # Convert grayscale image to RGB\n",
        "        elif image.shape[-1] != 3:\n",
        "            raise ValueError(f\"Unexpected image shape: {image.shape}\")\n",
        "\n",
        "        # Apply transformations\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Convert categories to tensors\n",
        "        categories = torch.zeros(self.num_categories, dtype=torch.float32)\n",
        "        for category in entry['categories']:\n",
        "            if category < self.num_categories:\n",
        "                categories[category] = 1.0\n",
        "\n",
        "        return image, categories\n",
        "\n",
        "# -------------------------\n",
        "# Load annotations\n",
        "# -------------------------\n",
        "def parse_annotations(csv_path):\n",
        "    \"\"\"\n",
        "    Load and parse annotations from a CSV file.\n",
        "\n",
        "    Args:\n",
        "        csv_path (str): Path to the CSV file containing annotations.\n",
        "\n",
        "    Returns:\n",
        "        list: List of annotations as dictionaries.\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "    annotations = []\n",
        "\n",
        "    # Adjust based on your CSV columns\n",
        "    category_columns = df.columns[9:39]\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        categories = [int(idx) for idx, val in enumerate(row[category_columns]) if val == 1]\n",
        "        annotation = {\n",
        "            'filename': row['Crop_name'],\n",
        "            'categories': categories,\n",
        "        }\n",
        "        annotations.append(annotation)\n",
        "\n",
        "    return annotations\n",
        "\n",
        "# -------------------------\n",
        "# Integration into training/validation pipeline\n",
        "# -------------------------\n",
        "def load_data(train_csv, val_csv, img_dir, batch_size=16, num_categories=26):\n",
        "    \"\"\"\n",
        "    Load training and validation data with DataLoader.\n",
        "\n",
        "    Args:\n",
        "        train_csv (str): Path to the CSV file for training annotations.\n",
        "        val_csv (str): Path to the CSV file for validation annotations.\n",
        "        img_dir (str): Directory containing the images.\n",
        "        batch_size (int): Batch size.\n",
        "        num_categories (int): Number of categories for multi-label classification.\n",
        "\n",
        "    Returns:\n",
        "        DataLoader, DataLoader: DataLoaders for training and validation datasets.\n",
        "    \"\"\"\n",
        "    train_annotations = parse_annotations(train_csv)\n",
        "    val_annotations = parse_annotations(val_csv)\n",
        "\n",
        "    transform = get_transform()\n",
        "\n",
        "    train_dataset = EMOTICDataset(train_annotations, img_dir, transform=transform, num_categories=num_categories)\n",
        "    val_dataset = EMOTICDataset(val_annotations, img_dir, transform=transform, num_categories=num_categories)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    base_dir = \"/root/.cache/kagglehub/datasets/magdawjcicka/emotic/versions/1\"\n",
        "    train_csv = os.path.join(base_dir, \"annots_arrs/annot_arrs_train.csv\")\n",
        "    val_csv = os.path.join(base_dir, \"annots_arrs/annot_arrs_test.csv\")\n",
        "    img_dir = os.path.join(base_dir, \"img_arrs\")\n",
        "\n",
        "    # Check if files exist\n",
        "    if not os.path.exists(train_csv):\n",
        "        raise FileNotFoundError(f\"Training CSV file not found: {train_csv}\")\n",
        "    if not os.path.exists(val_csv):\n",
        "        raise FileNotFoundError(f\"Validation CSV file not found: {val_csv}\")\n",
        "    if not os.path.exists(img_dir):\n",
        "        raise FileNotFoundError(f\"Image directory not found: {img_dir}\")\n",
        "\n",
        "    train_loader, val_loader = load_data(train_csv, val_csv, img_dir, batch_size=16)\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        print(\"Batch of images:\", images.shape)\n",
        "        print(\"Batch of labels:\", labels.shape)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CE6kAr6dlCsp",
        "outputId": "c354f02f-9fc4-41b6-c7d6-15331c5980ac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch of images: torch.Size([16, 3, 224, 224])\n",
            "Batch of labels: torch.Size([16, 26])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GIQLkfZlWDh",
        "outputId": "e166ab90-ae84-485f-99b3-403bf4cf058f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
        "\n",
        "# Load Vision Transformer model with weights\n",
        "class VisionTransformerEmotionModel(nn.Module):\n",
        "    def __init__(self, num_classes=26):\n",
        "        super(VisionTransformerEmotionModel, self).__init__()\n",
        "        self.vit = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)  # Use the correct weights argument\n",
        "        self.vit.heads.head = nn.Linear(self.vit.heads.head.in_features, num_classes)  # Update head for multi-label classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.vit(x)\n",
        "\n",
        "\n",
        "# Instantiate the model\n",
        "num_classes = 26\n",
        "model = VisionTransformerEmotionModel(num_classes=num_classes).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BA7RZHXflxGK",
        "outputId": "4cbd41f8-ab53-4433-d318-75bfaef92a4c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
            "100%|██████████| 330M/330M [00:02<00:00, 132MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vca_loss(logits, labels, alpha=0.1):\n",
        "    \"\"\"\n",
        "    Variance-Constrained Agreement (VCA) loss for multi-label classification.\n",
        "\n",
        "    Args:\n",
        "        logits (Tensor): Predicted logits (batch_size, num_classes).\n",
        "        labels (Tensor): Ground-truth labels (batch_size, num_classes).\n",
        "        alpha (float): Weight for the variance term.\n",
        "\n",
        "    Returns:\n",
        "        Tensor: Calculated VCA loss.\n",
        "    \"\"\"\n",
        "    # Apply sigmoid to logits to get probabilities\n",
        "    probabilities = torch.sigmoid(logits)\n",
        "\n",
        "    # Compute the mean squared error (agreement loss)\n",
        "    mean_agreement = torch.mean((probabilities - labels) ** 2)\n",
        "\n",
        "    # Compute the variance across the batch\n",
        "    variance = torch.var(probabilities, dim=0).mean()\n",
        "\n",
        "    # Combine the agreement loss and the variance term\n",
        "    return mean_agreement + alpha * variance\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, train_loader, optimizer, device, alpha=0.1, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model(images)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = vca_loss(logits, labels, alpha)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}\")"
      ],
      "metadata": {
        "id": "Uu076-1nl6kU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_model_with_progress_bar(model, train_loader, optimizer, device, alpha=0.1, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        # Ajouter tqdm pour afficher une barre de progression\n",
        "        progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "        for batch_idx, (images, labels) in progress_bar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model(images)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = vca_loss(logits, labels, alpha)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Mise à jour de la barre de progression\n",
        "            progress_bar.set_postfix({\"Batch Loss\": loss.item()})\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}] completed, Average Loss: {total_loss / len(train_loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM4Lxb9zn9os",
        "outputId": "c0ce0eb7-9b36-43b7-bd66-ed403b041d64"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "uutsA965l_3H"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model_with_progress_bar(model, train_loader, optimizer, device, alpha=0.1, num_epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITz_w6IlmDKn",
        "outputId": "6280206a-e2e3-454a-9b70-301d7204b23c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 1540/1540 [15:41<00:00,  1.64it/s, Batch Loss=0.0572]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] completed, Average Loss: 0.0568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 1540/1540 [15:23<00:00,  1.67it/s, Batch Loss=0.0642]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10] completed, Average Loss: 0.0562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 1540/1540 [15:27<00:00,  1.66it/s, Batch Loss=0.0442]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10] completed, Average Loss: 0.0558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 1540/1540 [15:25<00:00,  1.66it/s, Batch Loss=0.038]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10] completed, Average Loss: 0.0552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 1540/1540 [15:25<00:00,  1.66it/s, Batch Loss=0.0698]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10] completed, Average Loss: 0.0544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 1540/1540 [15:24<00:00,  1.67it/s, Batch Loss=0.0659]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10] completed, Average Loss: 0.0532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 1540/1540 [15:29<00:00,  1.66it/s, Batch Loss=0.0389]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10] completed, Average Loss: 0.0515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 1540/1540 [15:28<00:00,  1.66it/s, Batch Loss=0.0422]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10] completed, Average Loss: 0.0492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 1540/1540 [15:22<00:00,  1.67it/s, Batch Loss=0.0544]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10] completed, Average Loss: 0.0464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 1540/1540 [15:23<00:00,  1.67it/s, Batch Loss=0.0696]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10] completed, Average Loss: 0.0433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, val_loader, device, alpha=0.1):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    all_targets = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            logits = model(images)\n",
        "            loss = vca_loss(logits, labels, alpha)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Convert logits to probabilities\n",
        "            probabilities = torch.sigmoid(logits)\n",
        "            predictions = (probabilities > 0.5).float()\n",
        "\n",
        "            all_targets.append(labels.cpu().numpy())\n",
        "            all_predictions.append(predictions.cpu().numpy())\n",
        "\n",
        "    # Calculate average loss\n",
        "    avg_loss = total_loss / len(val_loader)\n",
        "\n",
        "    # Concatenate all targets and predictions\n",
        "    all_targets = np.vstack(all_targets)\n",
        "    all_predictions = np.vstack(all_predictions)\n",
        "\n",
        "    # Calculate precision, recall, and F1-score\n",
        "    from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "    precision = precision_score(all_targets, all_predictions, average=\"macro\")\n",
        "    recall = recall_score(all_targets, all_predictions, average=\"macro\")\n",
        "    f1 = f1_score(all_targets, all_predictions, average=\"macro\")\n",
        "\n",
        "    return avg_loss, precision, recall, f1\n",
        "\n",
        "val_loss, precision, recall, f1 = evaluate_model(model, val_loader, device, alpha=0.1)\n",
        "print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYwV8iIHNmhZ",
        "outputId": "65cc3a7d-cdce-4808-b338-adc413d09bf0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 455/455 [01:37<00:00,  4.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1205\n",
            "Precision: 0.2645, Recall: 0.0422, F1-Score: 0.0577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}