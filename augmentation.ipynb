{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3840d209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==2.0.3 in ./.venv/lib/python3.9/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy==1.24.3 in ./.venv/lib/python3.9/site-packages (1.24.3)\n",
      "Requirement already satisfied: matplotlib==3.7.2 in ./.venv/lib/python3.9/site-packages (3.7.2)\n",
      "Requirement already satisfied: seaborn==0.12.2 in ./.venv/lib/python3.9/site-packages (0.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.9/site-packages (from pandas==2.0.3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.9/site-packages (from pandas==2.0.3) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.venv/lib/python3.9/site-packages (from pandas==2.0.3) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib==3.7.2) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.9/site-packages (from matplotlib==3.7.2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.9/site-packages (from matplotlib==3.7.2) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib==3.7.2) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from matplotlib==3.7.2) (25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib==3.7.2) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib==3.7.2) (3.0.9)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib==3.7.2) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib==3.7.2) (3.23.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas==2.0.3) (1.17.0)\n",
      "Requirement already satisfied: pillow==10.0.0 in ./.venv/lib/python3.9/site-packages (10.0.0)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.9/site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (3.6.0)\n",
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch==2.1.0 in ./.venv/lib/python3.9/site-packages (2.1.0)\n",
      "Requirement already satisfied: torchvision==0.16.0 in ./.venv/lib/python3.9/site-packages (0.16.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.9/site-packages (from torch==2.1.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.9/site-packages (from torch==2.1.0) (4.14.1)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.9/site-packages (from torch==2.1.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.9/site-packages (from torch==2.1.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.9/site-packages (from torch==2.1.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.9/site-packages (from torch==2.1.0) (2024.6.1)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.9/site-packages (from torchvision==0.16.0) (1.24.3)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.9/site-packages (from torchvision==0.16.0) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.9/site-packages (from torchvision==0.16.0) (10.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.9/site-packages (from jinja2->torch==2.1.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./.venv/lib/python3.9/site-packages (from requests->torchvision==0.16.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests->torchvision==0.16.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests->torchvision==0.16.0) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests->torchvision==0.16.0) (2022.12.7)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.9/site-packages (from sympy->torch==2.1.0) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "EMOTIC Dataset Augmentation Pipeline with Visualizations\n",
    "Author: Enhanced for local Mac execution\n",
    "Dataset: EMOTIC (EMOTions In Context)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "!pip install pandas==2.0.3 numpy==1.24.3 matplotlib==3.7.2 seaborn==0.12.2\n",
    "!pip install pillow==10.0.0 scikit-learn tqdm\n",
    "!pip install torch==2.1.0 torchvision==0.16.0 --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38ecbc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# IMPORTS AND SETUP\n",
    "# ==============================================================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import random\n",
    "import logging\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use non-interactive backend\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff() \n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import math\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "# ==============================================================================\n",
    "EXCLUDED_CLASSES = [\"Engagement\", \"Happiness\", \"Anticipation\"]\n",
    "# EXCLUDED_CLASSES = [\"Engagement\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78ec7274",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetConfig:\n",
    "    \"\"\"Configuration for EMOTIC dataset paths.\"\"\"\n",
    "    # Dataset paths - Update these if your directory structure is different\n",
    "    TRAIN_ANNOTATIONS = \"archive/annots_arrs/annot_arrs_train.csv\"\n",
    "    VAL_ANNOTATIONS = \"archive/annots_arrs/annot_arrs_val.csv\"\n",
    "    IMG_DIR = \"archive/img_arrs/\"\n",
    "    OUTPUT_DIR = \"archive/augmented_img_arrs/\"\n",
    "    VIZ_DIR = \"visualizations/\"\n",
    "    \n",
    "    @classmethod\n",
    "    def check_paths(cls):\n",
    "        \"\"\"Verify that dataset paths exist.\"\"\"\n",
    "        paths_to_check = [\n",
    "            (cls.TRAIN_ANNOTATIONS, \"Training annotations\"),\n",
    "            (cls.VAL_ANNOTATIONS, \"Validation annotations\"),\n",
    "            (cls.IMG_DIR, \"Image directory\")\n",
    "        ]\n",
    "        \n",
    "        all_exist = True\n",
    "        for path, name in paths_to_check:\n",
    "            if not os.path.exists(path):\n",
    "                logging.error(f\"{name} not found at: {path}\")\n",
    "                all_exist = False\n",
    "            else:\n",
    "                logging.info(f\"✓ {name} found: {path}\")\n",
    "        \n",
    "        # Always recreate these two directories fresh\n",
    "        \n",
    "        for dir_path in [cls.OUTPUT_DIR, cls.VIZ_DIR]:\n",
    "            if os.path.exists(dir_path):\n",
    "                shutil.rmtree(dir_path)\n",
    "                logging.info(f\"✗ Cleared existing directory: {dir_path}\")\n",
    "            os.makedirs(dir_path)\n",
    "            logging.info(f\"✓ Created directory: {dir_path}\")\n",
    "    \n",
    "                \n",
    "        return all_exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e8bcf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Visualization Functions\n",
    "# -------------------------\n",
    "def plot_class_distribution(df, discrete_labels, minority_classes, majority_classes, save_path=\"visualizations/\"):\n",
    "    \"\"\"Plot class distribution bar chart with log scale option.\"\"\"\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    # Calculate class frequencies\n",
    "    class_counts = df[discrete_labels].sum().sort_values(ascending=False)\n",
    "    \n",
    "    # Create figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))\n",
    "    \n",
    "    # Linear scale plot\n",
    "    colors = ['red' if cls in minority_classes.index else 'green' for cls in class_counts.index]\n",
    "    bars1 = ax1.bar(range(len(class_counts)), class_counts.values, color=colors, alpha=0.7)\n",
    "    ax1.set_xticks(range(len(class_counts)))\n",
    "    ax1.set_xticklabels(class_counts.index, rotation=45, ha='right')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.set_title('Class Distribution (Linear Scale)')\n",
    "    ax1.axhline(y=class_counts.median(), color='blue', linestyle='--', label='Median', alpha=0.5)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Log scale plot for better minority class visibility\n",
    "    bars2 = ax2.bar(range(len(class_counts)), class_counts.values, color=colors, alpha=0.7)\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.set_xticks(range(len(class_counts)))\n",
    "    ax2.set_xticklabels(class_counts.index, rotation=45, ha='right')\n",
    "    ax2.set_ylabel('Frequency (log scale)')\n",
    "    ax2.set_title('Class Distribution (Log Scale) - Red: Minority, Green: Majority')\n",
    "    ax2.axhline(y=class_counts.median(), color='blue', linestyle='--', label='Median', alpha=0.5)\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, 'class_distribution.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close() \n",
    "    \n",
    "    logging.info(f\"Class distribution plot saved to {save_path}\")\n",
    "    return class_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b0a2976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_cooccurrence(df, discrete_labels, save_path=\"visualizations/\"):\n",
    "    \"\"\"Create heatmap showing emotion co-occurrence patterns.\"\"\"\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    # Calculate co-occurrence matrix\n",
    "    binary_data = df[discrete_labels].astype(int)\n",
    "    cooccurrence = binary_data.T.dot(binary_data)\n",
    "    \n",
    "    # Normalize by diagonal (self-occurrence)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        normalized_cooccurrence = cooccurrence / np.diag(cooccurrence)[:, None]\n",
    "        normalized_cooccurrence = np.nan_to_num(normalized_cooccurrence)\n",
    "    \n",
    "    # Create heatmap\n",
    "    plt.figure(figsize=(16, 14))\n",
    "    sns.heatmap(normalized_cooccurrence, \n",
    "                xticklabels=discrete_labels,\n",
    "                yticklabels=discrete_labels,\n",
    "                cmap='YlOrRd',\n",
    "                vmin=0, vmax=1,\n",
    "                square=True,\n",
    "                cbar_kws={'label': 'Co-occurrence Probability'},\n",
    "                fmt='.2f',\n",
    "                linewidths=0.5)\n",
    "    \n",
    "    plt.title('Emotion Co-occurrence Heatmap\\n(Probability of column emotion given row emotion)', fontsize=14)\n",
    "    plt.xlabel('Co-occurring Emotion', fontsize=12)\n",
    "    plt.ylabel('Primary Emotion', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, 'cooccurrence_heatmap.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close() \n",
    "    \n",
    "    logging.info(f\"Co-occurrence heatmap saved to {save_path}\")\n",
    "    return cooccurrence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5d18f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_label_count_distribution(df, discrete_labels, save_path=\"visualizations/\"):\n",
    "    \"\"\"Plot distribution of number of labels per image.\"\"\"\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    # Count labels per image\n",
    "    label_counts = df[discrete_labels].sum(axis=1)\n",
    "    count_distribution = Counter(label_counts)\n",
    "    \n",
    "    # Create bar plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    x_values = sorted(count_distribution.keys())\n",
    "    y_values = [count_distribution[x] for x in x_values]\n",
    "    \n",
    "    bars = ax.bar(x_values, y_values, color='steelblue', alpha=0.8, edgecolor='black')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, val in zip(bars, y_values):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{val}\\n({val/len(df)*100:.1f}%)',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    ax.set_xlabel('Number of Labels per Image', fontsize=12)\n",
    "    ax.set_ylabel('Number of Images', fontsize=12)\n",
    "    ax.set_title('Distribution of Multi-label Samples', fontsize=14)\n",
    "    ax.set_xticks(x_values)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add statistics\n",
    "    mean_labels = label_counts.mean()\n",
    "    median_labels = label_counts.median()\n",
    "    ax.axvline(x=mean_labels, color='red', linestyle='--', label=f'Mean: {mean_labels:.2f}', alpha=0.7)\n",
    "    ax.axvline(x=median_labels, color='green', linestyle='--', label=f'Median: {median_labels:.1f}', alpha=0.7)\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, 'label_count_distribution.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close() \n",
    "    \n",
    "    logging.info(f\"Label count distribution saved to {save_path}\")\n",
    "    return count_distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "19bc6619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_minority_analysis(df, discrete_labels, minority_classes, majority_classes, exclude_classes, save_path=\"visualizations/\"):\n",
    "    \"\"\"Analyze and visualize minority vs majority class distribution in samples.\"\"\"\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    # Categorize each sample\n",
    "    minority_only = 0\n",
    "    majority_only = 0\n",
    "    mixed = 0\n",
    "    \n",
    "    minority_indices = [discrete_labels.get_loc(cls) for cls in minority_classes.index]\n",
    "    majority_indices = [discrete_labels.get_loc(cls) for cls in majority_classes.index if cls not in exclude_classes]\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        labels = row[discrete_labels]\n",
    "        has_minority = any(labels.iloc[idx] == 1 for idx in minority_indices)\n",
    "        has_majority = any(labels.iloc[idx] == 1 for idx in majority_indices)\n",
    "        \n",
    "        if has_minority and not has_majority:\n",
    "            minority_only += 1\n",
    "        elif has_majority and not has_minority:\n",
    "            majority_only += 1\n",
    "        elif has_minority and has_majority:\n",
    "            mixed += 1\n",
    "    \n",
    "    # Create donut chart\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "    \n",
    "    # Donut chart\n",
    "    sizes = [minority_only, mixed, majority_only]\n",
    "    labels = ['Minority Only', 'Mixed (Minority + Majority)', 'Majority Only']\n",
    "    colors = ['#ff6b6b', '#ffd93d', '#6bcf7f']\n",
    "    explode = (0.05, 0.05, 0)\n",
    "    \n",
    "    wedges, texts, autotexts = ax1.pie(sizes, labels=labels, colors=colors, \n",
    "                                         autopct=lambda pct: f'{pct:.1f}%\\n({int(pct/100*len(df))})',\n",
    "                                         explode=explode, startangle=90,\n",
    "                                         textprops={'fontsize': 10})\n",
    "    \n",
    "    # Create donut effect\n",
    "    centre_circle = plt.Circle((0, 0), 0.70, fc='white')\n",
    "    ax1.add_artist(centre_circle)\n",
    "    ax1.set_title('Sample Distribution Analysis', fontsize=14, pad=20)\n",
    "    \n",
    "    # Bar chart for better comparison\n",
    "    ax2.bar(labels, sizes, color=colors, alpha=0.8, edgecolor='black')\n",
    "    for i, (label, size) in enumerate(zip(labels, sizes)):\n",
    "        ax2.text(i, size, f'{size}\\n({size/len(df)*100:.1f}%)', \n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    ax2.set_ylabel('Number of Samples', fontsize=12)\n",
    "    ax2.set_title('Sample Category Distribution', fontsize=14)\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, 'minority_analysis.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()  \n",
    "    \n",
    "    logging.info(f\"Minority analysis saved to {save_path}\")\n",
    "    logging.info(f\"Minority only: {minority_only}, Mixed: {mixed}, Majority only: {majority_only}\")\n",
    "    \n",
    "    return minority_only, mixed, majority_only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bc6b3cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_imbalance_ratio(minority_classes, majority_classes, save_path=\"visualizations/\"):\n",
    "    \"\"\"Visualize imbalance ratio for each class.\"\"\"\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    # Combine all classes\n",
    "    all_classes = pd.concat([minority_classes, majority_classes])\n",
    "    max_count = all_classes.max()\n",
    "    \n",
    "    # Calculate imbalance ratio (max_count / class_count)\n",
    "    imbalance_ratios = max_count / all_classes\n",
    "    imbalance_ratios = imbalance_ratios.sort_values(ascending=False)\n",
    "    \n",
    "    # Create color map based on severity\n",
    "    colors = []\n",
    "    for ratio in imbalance_ratios.values:\n",
    "        if ratio > 10:\n",
    "            colors.append('#d32f2f')  # Severe imbalance (red)\n",
    "        elif ratio > 5:\n",
    "            colors.append('#ff9800')  # Moderate imbalance (orange)\n",
    "        elif ratio > 2:\n",
    "            colors.append('#ffc107')  # Mild imbalance (yellow)\n",
    "        else:\n",
    "            colors.append('#4caf50')  # Balanced (green)\n",
    "    \n",
    "    # Create horizontal bar chart\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    y_pos = np.arange(len(imbalance_ratios))\n",
    "    bars = ax.barh(y_pos, imbalance_ratios.values, color=colors, alpha=0.8, edgecolor='black')\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, val) in enumerate(zip(bars, imbalance_ratios.values)):\n",
    "        width = bar.get_width()\n",
    "        label = f'{val:.1f}x'\n",
    "        ax.text(width, bar.get_y() + bar.get_height()/2., label,\n",
    "                ha='left', va='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(imbalance_ratios.index, fontsize=10)\n",
    "    ax.set_xlabel('Imbalance Ratio (Max Count / Class Count)', fontsize=12)\n",
    "    ax.set_title('Class Imbalance Severity Analysis', fontsize=14)\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Add legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='#d32f2f', label='Severe (>10x)'),\n",
    "        Patch(facecolor='#ff9800', label='Moderate (5-10x)'),\n",
    "        Patch(facecolor='#ffc107', label='Mild (2-5x)'),\n",
    "        Patch(facecolor='#4caf50', label='Balanced (<2x)')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='lower right')\n",
    "    \n",
    "    # Add reference lines\n",
    "    ax.axvline(x=2, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax.axvline(x=5, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax.axvline(x=10, color='gray', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, 'imbalance_ratio.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    logging.info(f\"Imbalance ratio plot saved to {save_path}\")\n",
    "    return imbalance_ratios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "415198ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_augmentation_report(class_counts, minority_classes, filtered_annotations, save_path=\"visualizations/\"):\n",
    "    \"\"\"Generate a summary report of augmentation strategy.\"\"\"\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    report = []\n",
    "    report.append(\"=\" * 60)\n",
    "    report.append(\"AUGMENTATION STRATEGY REPORT\")\n",
    "    report.append(\"=\" * 60)\n",
    "    report.append(f\"\\nTotal Classes: {len(class_counts)}\")\n",
    "    report.append(f\"Minority Classes: {len(minority_classes)}\")\n",
    "    report.append(f\"Images Selected for Augmentation: {len(filtered_annotations)}\")\n",
    "    report.append(\"\\n\" + \"-\" * 40)\n",
    "    report.append(\"MINORITY CLASSES REQUIRING AUGMENTATION:\")\n",
    "    report.append(\"-\" * 40)\n",
    "    \n",
    "    for cls, count in minority_classes.items():\n",
    "        weight = sum(minority_classes.values) / count\n",
    "        report.append(f\"  {cls:20s}: {int(count):5d}  samples → {weight:.1f}x augmentation\")\n",
    "    \n",
    "    report_text = \"\\n\".join(report)\n",
    "    \n",
    "    # Save report\n",
    "    with open(os.path.join(save_path, 'augmentation_report.txt'), 'w') as f:\n",
    "        f.write(report_text)\n",
    "    \n",
    "    print(report_text)\n",
    "    return report_text\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Helper Functions\n",
    "# -------------------------\n",
    "def detect_minority_classes(csv_path, exclude_classes=EXCLUDED_CLASSES, threshold=2000):\n",
    "    \"\"\"Detect minority classes and their distribution.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Get emotion columns specifically (columns 8-33, total of 26 emotion labels)\n",
    "    emotion_start_idx = 8\n",
    "    emotion_end_idx = 34  # exclusive, so includes up to index 33\n",
    "    emotion_columns = df.columns[emotion_start_idx:emotion_end_idx].tolist()\n",
    "    \n",
    "    # Double-check by excluding known non-emotion columns\n",
    "    non_emotion_columns = ['X_min', 'Y_min', 'X_max', 'Y_max', 'Arr_name', 'Crop_name']\n",
    "    emotion_labels = [col for col in emotion_columns if col not in non_emotion_columns]\n",
    "    \n",
    "    print(f\"Identified emotion columns ({len(emotion_labels)}): {emotion_labels}\")\n",
    "    \n",
    "    # Calculate class frequencies for emotion labels only\n",
    "    numeric_data = df[emotion_labels].apply(pd.to_numeric, errors='coerce')\n",
    "    class_counts = numeric_data.sum()\n",
    "\n",
    "    # Use 2000 as threshold instead of median\n",
    "    threshold_value = threshold\n",
    "    \n",
    "    # Identify minority and majority classes\n",
    "    minority_classes = class_counts[class_counts < threshold_value]\n",
    "    majority_classes = class_counts[class_counts >= threshold_value]\n",
    "\n",
    "    # Exclude specific classes from majority\n",
    "    majority_classes = majority_classes.drop(exclude_classes, errors='ignore')\n",
    "\n",
    "    logging.info(f\"Total emotion labels found: {len(emotion_labels)}\")\n",
    "    logging.info(f\"Threshold used: {threshold_value} instances\")\n",
    "    logging.info(f\"Minority Classes (<{threshold_value}): {list(minority_classes.index)}\")\n",
    "    logging.info(f\"Majority Classes (>={threshold_value}): {list(majority_classes.index)}\")\n",
    "\n",
    "    return minority_classes, majority_classes\n",
    "\n",
    "def filter_minority_annotations(df, minority_classes, exclude_classes):\n",
    "    \"\"\"Filter annotations for images containing minority classes, excluding majority classes.\"\"\"\n",
    "    discrete_labels = df.columns[8:34]\n",
    "    minority_indices = [discrete_labels.get_loc(cls) for cls in minority_classes.index]\n",
    "    exclude_indices = [discrete_labels.get_loc(cls) for cls in exclude_classes if cls in discrete_labels]\n",
    "\n",
    "    filtered_annotations = []\n",
    "    for _, row in df.iterrows():\n",
    "        labels = row[discrete_labels]\n",
    "        is_minority = any(labels.iloc[idx] == 1 for idx in minority_indices)\n",
    "        overlaps_majority = any(labels.iloc[idx] == 1 for idx in exclude_indices)\n",
    "\n",
    "        if is_minority and not overlaps_majority:\n",
    "            filtered_annotations.append(row)\n",
    "\n",
    "    logging.info(f\"Filtered {len(filtered_annotations)} images for augmentation.\")\n",
    "    return pd.DataFrame(filtered_annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e73fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -------------------------\n",
    "# Augmentation Class\n",
    "# -------------------------\n",
    "class Augmentation:\n",
    "    def __init__(self, img_dir, output_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "            transforms.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0)),\n",
    "        ])\n",
    "\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "    def augment_and_save(self, annotations, minority_classes):\n",
    "        total_minority = sum(minority_classes.values)\n",
    "        class_weights = {cls: total_minority / freq for cls, freq in minority_classes.items()}\n",
    "\n",
    "        # --- Dynamic cap based on distribution (90th percentile) ---\n",
    "        # Ensures super-rare classes don't explode augmentation counts\n",
    "        _cap_percentile = 70\n",
    "        _weights_array = np.array(list(class_weights.values()), dtype=float)\n",
    "        # Optional safety: drop non-finite values (in case any freq == 0)\n",
    "        _weights_array = _weights_array[np.isfinite(_weights_array)]\n",
    "        cap = np.percentile(_weights_array, _cap_percentile) if len(_weights_array) else 1.0\n",
    "        cap = max(1.0, cap)  # never below 1\n",
    "        # -----------------------------------------------------------\n",
    "        \n",
    "        aug_counter = Counter()\n",
    "        print(\"\\nAugmenting images...\")\n",
    "        for _, row in tqdm(annotations.iterrows(), total=len(annotations), desc=\"Processing\"):\n",
    "            img_path = os.path.join(self.img_dir, row['Crop_name'])\n",
    "            if not os.path.exists(img_path):\n",
    "                logging.warning(f\"Image not found: {img_path}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                image = np.load(img_path)\n",
    "                if len(image.shape) == 2:\n",
    "                    image = np.stack([image] * 3, axis=-1)\n",
    "                elif image.shape[-1] != 3:\n",
    "                    raise ValueError(f\"Unexpected image shape: {image.shape}\")\n",
    "\n",
    "                pil_image = Image.fromarray(image.astype(np.uint8))\n",
    "\n",
    "                discrete_cols = annotations.columns[8:34]\n",
    "                categories = [discrete_cols[idx] for idx, val in enumerate(row[8:34]) if val == 1]\n",
    "\n",
    "                weight = 1\n",
    "                for cat in categories:\n",
    "                    if cat in minority_classes.index:\n",
    "                        weight = max(weight, class_weights.get(cat, 1))\n",
    "                num_augmentations = int(min(weight, cap))\n",
    "\n",
    "\n",
    "                for i in range(num_augmentations):\n",
    "                    augmented_image = self.transform(pil_image)\n",
    "                    base_name = row['Crop_name'].replace('.npy', '')\n",
    "                    output_path = os.path.join(self.output_dir, f\"aug_{i}_{base_name}.npy\")\n",
    "                    np.save(output_path, np.array(augmented_image))\n",
    "                \n",
    "                # Count augmented samples per class (only for classes present in this image)\n",
    "                for cat in categories:\n",
    "                    aug_counter[cat] += num_augmentations\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error augmenting image {img_path}: {str(e)}\")\n",
    "        \n",
    "        # Save the augmentation report (label, augmented_count)\n",
    "        viz_dir = Path(DatasetConfig.VIZ_DIR)\n",
    "        viz_dir.mkdir(parents=True, exist_ok=True)\n",
    "        import pandas as pd\n",
    "        rep = pd.DataFrame({\"label\": list(aug_counter.keys()),\n",
    "                            \"augmented_count\": list(aug_counter.values())})\n",
    "        rep.to_csv(viz_dir / \"augmentation_report.csv\", index=False)\n",
    "        return rep\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3194cdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_before_after_counts(df_train, discrete_labels):\n",
    "    import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "    from pathlib import Path\n",
    "\n",
    "    report_csv = Path(DatasetConfig.VIZ_DIR) / \"augmentation_report.csv\"\n",
    "    orig_counts = df_train[discrete_labels].sum().astype(int).rename(\"original_count\").to_frame()\n",
    "\n",
    "    if report_csv.exists():\n",
    "        rep = pd.read_csv(report_csv)\n",
    "        aug_counts = rep.set_index(\"label\")[\"augmented_count\"].astype(int).rename(\"augmented_count\")\n",
    "    else:\n",
    "        aug_counts = pd.Series(0, index=orig_counts.index, name=\"augmented_count\")\n",
    "\n",
    "    summary = orig_counts.join(aug_counts, how=\"left\").fillna(0).astype(int)\n",
    "    summary[\"post_count\"] = summary[\"original_count\"] + summary[\"augmented_count\"]\n",
    "\n",
    "    summary_sorted = summary.sort_values(\"post_count\", ascending=False)\n",
    "    idx = np.arange(len(summary_sorted)); width = 0.45\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.bar(idx - width/2, summary_sorted[\"original_count\"].values, width, label=\"Before\")\n",
    "    plt.bar(idx + width/2, summary_sorted[\"post_count\"].values, width, label=\"After (Original + Augmented)\")\n",
    "    plt.xticks(idx, summary_sorted.index, rotation=80, ha=\"right\")\n",
    "    plt.ylabel(\"Count\"); plt.title(\"Per-class counts: Before vs After Augmentation\")\n",
    "    plt.legend(); plt.tight_layout()\n",
    "    Path(DatasetConfig.VIZ_DIR).mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(Path(DatasetConfig.VIZ_DIR) / \"per_class_counts_before_vs_after.png\", dpi=200)\n",
    "    plt.close()  # Close the plot to free memory\n",
    "    print(\"Plot saved to:\", Path(DatasetConfig.VIZ_DIR) / \"per_class_counts_before_vs_after.png\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fbebd98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------\n",
    "# Main Function\n",
    "# -------------------------\n",
    "def main():\n",
    "    \"\"\"Main execution function for the augmentation pipeline.\"\"\"\n",
    "    \n",
    "    # Check if paths exist\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EMOTIC DATASET AUGMENTATION PIPELINE\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\n[Setup] Checking dataset paths...\")\n",
    "    \n",
    "    if not DatasetConfig.check_paths():\n",
    "        print(\"\\n❌ Error: Some required paths are missing.\")\n",
    "        print(\"Please ensure the 'archive' folder is in the current directory with:\")\n",
    "        print(\"  - archive/annots_arrs/annot_arrs_train.csv\")\n",
    "        print(\"  - archive/annots_arrs/annot_arrs_val.csv\")\n",
    "        print(\"  - archive/img_arrs/\")\n",
    "        return\n",
    "    \n",
    "    # Use configuration paths\n",
    "    annotations_path = DatasetConfig.TRAIN_ANNOTATIONS\n",
    "    img_dir = DatasetConfig.IMG_DIR\n",
    "    output_dir = DatasetConfig.OUTPUT_DIR\n",
    "    viz_dir = DatasetConfig.VIZ_DIR\n",
    "\n",
    "    # Load annotations\n",
    "    annotations = pd.read_csv(annotations_path)\n",
    "    discrete_labels = annotations.columns[8:34]\n",
    "    \n",
    "    print(f\"\\n[Data] Loaded {len(annotations)} training samples\")\n",
    "    print(f\"[Data] Found {len(discrete_labels)} emotion categories\")\n",
    "    \n",
    "    # Step 1: Detect minority and majority classes\n",
    "    print(\"\\n[Step 1] Detecting minority and majority classes...\")\n",
    "    minority_classes, majority_classes = detect_minority_classes(annotations_path, exclude_classes=EXCLUDED_CLASSES)\n",
    "    \n",
    "    # Visualization 1: Class Distribution\n",
    "    print(\"\\n[Visualization 1/5] Generating class distribution plots...\")\n",
    "    class_counts = plot_class_distribution(annotations, discrete_labels, minority_classes, majority_classes, viz_dir)\n",
    "    \n",
    "    # Visualization 2: Class Co-occurrence Heatmap\n",
    "    print(\"\\n[Visualization 2/5] Generating co-occurrence heatmap...\")\n",
    "    cooccurrence = plot_class_cooccurrence(annotations, discrete_labels, viz_dir)\n",
    "    \n",
    "    # Visualization 3: Label Count Distribution\n",
    "    print(\"\\n[Visualization 3/5] Analyzing multi-label distribution...\")\n",
    "    label_distribution = plot_label_count_distribution(annotations, discrete_labels, viz_dir)\n",
    "    \n",
    "    # Step 2: Filter annotations for minority class images\n",
    "    print(\"\\n[Step 2] Filtering annotations for minority class images...\")\n",
    "    filtered_annotations = filter_minority_annotations(annotations, minority_classes, EXCLUDED_CLASSES)\n",
    "    \n",
    "    # Visualization 4: Minority vs Majority Analysis\n",
    "    print(\"\\n[Visualization 4/5] Analyzing minority/majority sample distribution...\")\n",
    "    minority_only, mixed, majority_only = plot_minority_analysis(\n",
    "        annotations, discrete_labels, minority_classes, majority_classes, EXCLUDED_CLASSES, viz_dir\n",
    "    )\n",
    "    \n",
    "    # Visualization 5: Class Imbalance Ratio\n",
    "    print(\"\\n[Visualization 5/5] Computing class imbalance ratios...\")\n",
    "    imbalance_ratios = plot_class_imbalance_ratio(minority_classes, majority_classes, viz_dir)\n",
    "    \n",
    "    \n",
    "    # Step 3: Perform augmentation\n",
    "    print(\"\\n[Step 3] Starting augmentation process...\")\n",
    "    augmenter = Augmentation(img_dir, output_dir)\n",
    "\n",
    "    # This now returns the actual augmentation counts DataFrame\n",
    "    augmentation_report = augmenter.augment_and_save(filtered_annotations, minority_classes)\n",
    "\n",
    "    # Now plot the before vs after chart using the new report\n",
    "    plot_before_after_counts(annotations, list(discrete_labels))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"AUGMENTATION COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"✓ Augmented {len(filtered_annotations)} images\")\n",
    "    print(f\"✓ Visualizations saved to: {viz_dir}\")\n",
    "    print(f\"✓ Augmented images saved to: {output_dir}\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4274821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 16:58:16,896 - INFO - ✓ Training annotations found: archive/annots_arrs/annot_arrs_train.csv\n",
      "2025-08-18 16:58:16,896 - INFO - ✓ Validation annotations found: archive/annots_arrs/annot_arrs_val.csv\n",
      "2025-08-18 16:58:16,897 - INFO - ✓ Image directory found: archive/img_arrs/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EMOTIC DATASET AUGMENTATION PIPELINE\n",
      "============================================================\n",
      "\n",
      "[Setup] Checking dataset paths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 16:58:30,987 - INFO - ✗ Cleared existing directory: archive/augmented_img_arrs/\n",
      "2025-08-18 16:58:30,988 - INFO - ✓ Created directory: archive/augmented_img_arrs/\n",
      "2025-08-18 16:58:30,989 - INFO - ✗ Cleared existing directory: visualizations/\n",
      "2025-08-18 16:58:30,989 - INFO - ✓ Created directory: visualizations/\n",
      "2025-08-18 16:58:31,094 - INFO - Total emotion labels found: 26\n",
      "2025-08-18 16:58:31,095 - INFO - Threshold used: 2000 instances\n",
      "2025-08-18 16:58:31,095 - INFO - Minority Classes (<2000): ['Peace', 'Affection', 'Esteem', 'Surprise', 'Sympathy', 'Doubt/Confusion', 'Disconnection', 'Fatigue', 'Embarrassment', 'Yearning', 'Disapproval', 'Aversion', 'Annoyance', 'Anger', 'Sensitivity', 'Sadness', 'Disquietment', 'Fear', 'Pain', 'Suffering']\n",
      "2025-08-18 16:58:31,095 - INFO - Majority Classes (>=2000): ['Confidence', 'Pleasure', 'Excitement']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Data] Loaded 24639 training samples\n",
      "[Data] Found 26 emotion categories\n",
      "\n",
      "[Step 1] Detecting minority and majority classes...\n",
      "Identified emotion columns (26): ['Peace', 'Affection', 'Esteem', 'Anticipation', 'Engagement', 'Confidence', 'Happiness', 'Pleasure', 'Excitement', 'Surprise', 'Sympathy', 'Doubt/Confusion', 'Disconnection', 'Fatigue', 'Embarrassment', 'Yearning', 'Disapproval', 'Aversion', 'Annoyance', 'Anger', 'Sensitivity', 'Sadness', 'Disquietment', 'Fear', 'Pain', 'Suffering']\n",
      "\n",
      "[Visualization 1/5] Generating class distribution plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 16:58:32,168 - INFO - Class distribution plot saved to visualizations/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Visualization 2/5] Generating co-occurrence heatmap...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 16:58:33,222 - INFO - Co-occurrence heatmap saved to visualizations/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Visualization 3/5] Analyzing multi-label distribution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 16:58:33,621 - INFO - Label count distribution saved to visualizations/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 2] Filtering annotations for minority class images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 16:58:36,923 - INFO - Filtered 4098 images for augmentation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Visualization 4/5] Analyzing minority/majority sample distribution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 16:58:40,731 - INFO - Minority analysis saved to visualizations/\n",
      "2025-08-18 16:58:40,731 - INFO - Minority only: 6396, Mixed: 2477, Majority only: 6341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Visualization 5/5] Computing class imbalance ratios...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 16:58:41,394 - INFO - Imbalance ratio plot saved to visualizations/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 3] Starting augmentation process...\n",
      "\n",
      "Augmenting images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 4098/4098 [01:59<00:00, 34.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to: visualizations/per_class_counts_before_vs_after.png\n",
      "\n",
      "============================================================\n",
      "AUGMENTATION COMPLETE\n",
      "============================================================\n",
      "✓ Augmented 4098 images\n",
      "✓ Visualizations saved to: visualizations/\n",
      "✓ Augmented images saved to: archive/augmented_img_arrs/\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Execution\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the main pipeline\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
